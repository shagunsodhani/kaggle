{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, scaler=None):\n",
    "    '''Standardize features by removing the mean and scaling to unit variance'''\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    return scaler.transform(X), scaler\n",
    "\n",
    "def preprocess_labels(y, encoder=None, categorical=True):\n",
    "    '''Encode labels with value between 0 and n_classes-1.'''\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(y)\n",
    "    labels = encoder.transform(y).astype(np.int32)\n",
    "    if categorical:\n",
    "        labels = np_utils.to_categorical(labels)\n",
    "    return labels, encoder\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    data = df.values\n",
    "    np.random.shuffle(data)\n",
    "    X = data[:, 1:-1].astype(np.float32)\n",
    "    y = data[:, -1]\n",
    "    y, _ = preprocess_labels(y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5)\n",
    "    x_train, scaler = preprocess_data(x_train)\n",
    "#     we use only the training data to normalize the data.\n",
    "    x_test, _ = preprocess_data(x_test, scaler)\n",
    "    x_val, _ = preprocess_data(x_val, scaler)\n",
    "    return ((x_train, y_train),\n",
    "            (x_val, y_val),\n",
    "            (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"data/train.csv\"\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_data(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions = 93\n",
      "Number of classes = 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of dimensions =\", x_train.shape[1])\n",
    "print(\"Number of classes =\", y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
